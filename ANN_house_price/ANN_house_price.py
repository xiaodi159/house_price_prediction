"""
    æˆ¿ä»·é¢„æµ‹


"""
import time
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset      # æ•°æ®é›†å¯¹è±¡.   æ•°æ® -> Tensor -> æ•°æ®é›† -> æ•°æ®åŠ è½½å™¨
from torch.utils.data import DataLoader         # æ•°æ®åŠ è½½å™¨.
from sklearn.preprocessing import StandardScaler, LabelEncoder



def creat_data():
    data = pd.read_csv('./data/HousePrice.csv', encoding='utf-8')
    # print(data.head())
    #ç‰¹å¾ç±»åˆ«
    # print(data.info())

    #æŸå¤±å€¼å¤„ç†
    #ç»Ÿè®¡æ¯åˆ—ç¼ºå¤±å€¼ä¸ªæ•°ï¼Œå…¨0->æ— ç¼ºå¤±å€¼
    miss_count = data.isnull().sum()
    # print(miss_count)
    num_cols = data.select_dtypes(include=[np.number]).columns
    for col in num_cols:
        mean_value = data[col].mean()
        data[col] = data[col].fillna(mean_value)

    #ç±»å‹è½¬æ¢ï¼Œå°†objectç±»å‹è½¬æ¢ä¸ºæ•°å­—ç±»å‹ä»£æ›¿
    cat_cols = data.select_dtypes(include=['object']).columns
    # print(cat_cols)

    # ç”¨äºä¿å­˜æ‰€æœ‰åˆ—çš„æ˜ å°„å…³ç³»
    category_maps = {}

    for col in cat_cols:
        unique_calues = data[col].dropna().unique()
        # enumerate:
        # ä¸ºæ¯ä¸ªç±»åˆ«åˆ†é…ä¸€ä¸ªæ•´æ•°ç¼–å·
        # å¦‚ {'RL':0, 'RM':1, 'FV':2}
        mapping_dict = {value: idx for idx, value in enumerate(unique_calues)}
        #ä¿å­˜æ˜ å°„å­—å­—å…¸
        category_maps[col] = mapping_dict
        #å¯¹æ•°å€¼è¿›è¡Œæ˜ å°„
        data[col] = data[col].map(mapping_dict)
        data[col] = data[col].fillna(-1)

    #ç‰¹å¾æå–
    x = data.iloc[:, 1:]
    y = data.iloc[:, 0]

    #æ·»åŠ ä¿å­˜è¾“å…¥ç‰¹å¾ç±»åˆ«
    feature_names = x.columns.tolist()

    # values: DataFrame â†’ ndarray
    x = x.values.astype(np.float32)
    y = y.values.astype(np.float32)

    #æ•°æ®åˆ’åˆ†
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=24)

    #æ•°æ®æ ‡å‡†åŒ–å¤„ç†(è½¬æ¢å™¨ï¼‰
    # (ä¼˜åŒ–ï¼‰ åˆ†åˆ«å¯¹ç‰¹å¾å’Œç›®æ ‡è¿›è¡Œæ ‡å‡†åŒ–
    transfer_x = StandardScaler()
    x_train = transfer_x.fit_transform(x_train)
    x_test = transfer_x.transform(x_test)

    transfer_y = StandardScaler()
    y_train = transfer_y.fit_transform(y_train.reshape(-1, 1))
    y_test = transfer_y.transform(y_test.reshape(-1, 1))
    #æŠŠ y ä»â€œäºŒç»´æ•°ç»„â€å˜æˆâ€œä¸€ç»´æµ®ç‚¹æ•°ç»„â€
    y_train = y_train.astype(np.float32).ravel()
    y_test = y_test.astype(np.float32).ravel()


    # print(x_train.shape, x_test.shape)

    #æ•°æ®å°è£…
    train_dataset = TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))
    test_dataset = TensorDataset(torch.Tensor(x_test), torch.Tensor(y_test))

    #è¿”å›å€¼ï¼šè®­ç»ƒé›†ï¼Œæµ‹è¯•é›†ï¼Œï¼ˆæ˜ å°„ï¼Œå­—å…¸ï¼‰ï¼Œè¾“å…¥ç‰¹å¾å€¼æ•°å­—
    #æ·»åŠ è¾“å‡ºï¼Œç‰¹å¾ç±»åˆ«ï¼Œ è½¬æ¢å™¨(x,å’Œyï¼‰
    return train_dataset, test_dataset, category_maps, x_train.shape[1], feature_names, transfer_x, transfer_y



class ANN_house_price(nn.Module):
    def __init__(self, input_dim):
        #åˆå§‹åŒ–çˆ¶ç±»
        super().__init__()

        self.Linear1 = nn.Linear(in_features=input_dim, out_features=256)
        # æ‰¹é‡å½’ä¸€åŒ–
        self.bn1 = nn.BatchNorm1d(256)
        #æ­£åˆ™åŒ–
        self.dropout1 = nn.Dropout(0.4)
        self.Linear2 = nn.Linear(in_features=256, out_features=128)
        self.bn2 = nn.BatchNorm1d(128)
        self.dropout2 = nn.Dropout(0.4)
        self.Linear3 = nn.Linear(in_features=128, out_features=64)
        self.bn3 = nn.BatchNorm1d(64)
        self.dropout3 = nn.Dropout(0.4)
        self.output = nn.Linear(in_features=64, out_features=1)

    #å®šä¹‰å‰å‘ä¼ æ’­å‡½æ•°
    def forward(self, x):
        x = torch.relu(self.bn1(self.Linear1(x)))
        x = self.dropout1(x)
        x = torch.relu(self.bn2(self.Linear2(x)))
        x = self.dropout2(x)
        x = torch.relu(self.bn3(self.Linear3(x)))
        x = self.dropout3(x)
        x = self.output(x)
        return x


def train(train_dataset, input_dim, epoch):
    model = ANN_house_price(input_dim)
    model.train()
    # æ•°æ®é›†å¯¹è±¡
    # å‚1: æ•°æ®é›†å¯¹è±¡(1600æ¡), å‚2: æ¯æ‰¹æ¬¡çš„æ•°æ®æ¡æ•°, å‚3: æ˜¯å¦æ‰“ä¹±æ•°æ®(è®­ç»ƒé›†: æ‰“ä¹±, æµ‹è¯•é›†: ä¸æ‰“ä¹±)
    train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)

    #ä¼˜åŒ–æŸå¤±å‡½æ•°
    # criterion = nn.L1Loss()
    criterion = nn.MSELoss()

    #L2 æ­£åˆ™
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)

    for epoch in range(epoch):
        total_loss, mean_loss = 0.0, 0.0
        start = time.time()
        for x, y in train_loader:

            y = y.view(-1, 1)

            y_pred = model(x)
            # print(y.shape, y_pred.shape)

            loss = criterion(y_pred, y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        mean_loss = total_loss / len(train_loader)
        print(f'Epoch {epoch +1} Loss {mean_loss:.4f} Time {time.time() - start:.2f}s')

    #ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), './model/ANN_house_price.pth')

def evaluate(test_dataset, input_dim):
    #åŠ è½½æ¨¡å‹å‚æ•°
    model = ANN_house_price(input_dim)
    model.load_state_dict(torch.load('./model/ANN_house_price.pth'))
    model.eval()

    test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)

    #å®šä¹‰è¯„ä¼°æŒ‡æ ‡
    #å¹³å‡ç»å¯¹è¯¯å·®
    mae_loss = nn.L1Loss()
    #å‡æ–¹è¯¯å·®
    mse_loss = nn.MSELoss()

    total_mae = 0.0
    total_mse = 0.0

    y_true_list, y_pred_list = [], []

    with torch.no_grad():
        for x, y in test_loader:
            y = y.view(-1, 1)
            y_pred = model(x)

            total_mae += mae_loss(y_pred, y).item()
            total_mse += mse_loss(y_pred, y).item()

            #ä¿å­˜é¢„æµ‹å€¼ä¸çœŸå®å€¼
            y_true_list.append(y.numpy())
            y_pred_list.append(y_pred.numpy())

    #è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    mean_mae = total_mae / len(test_loader)
    mean_mse = total_mse / len(test_loader)
    r_mse = np.sqrt(mean_mse)

    y_pred = np.vstack(y_pred_list)
    y_true = np.vstack(y_true_list)

    # RÂ² = 1 - SSE / SST
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    r2 = 1 - ss_res / ss_tot

    #æ‰“å°é¢„ä¼°ç»“æœ
    print("========= æ¨¡å‹è¯„ä¼°ç»“æœ =========")
    print(f"MAE  : {mean_mae:.4f}")
    print(f"MSE  : {mean_mse:.4f}")
    print(f"RMSE : {r_mse:.4f}")
    print(f"RÂ²   : {r2:.4f}")


def predict_house_price(input_dim, feature_names, scaler_x, scaler_y, category_maps):
    model = ANN_house_price(input_dim)
    model.load_state_dict(torch.load('./model/ANN_house_price.pth'))
    model.eval()

    print("\nè¯·è¾“å…¥æˆ¿å±‹ç‰¹å¾ï¼ˆæŒ‰æç¤ºè¾“å…¥ï¼‰ï¼š")
    user_input = []

    for feature in feature_names:
        if feature in category_maps:
            mapping = category_maps[feature]
            print(f"\nç‰¹å¾ï¼š{feature}")
            for k, v in mapping.items():
                print(f"  {k} â†’ {v}")
            val = input("è¯·è¾“å…¥ç±»åˆ«åç§°ï¼š")
            while val not in mapping:
                val = input("è¯·è¾“å…¥ç±»åˆ«åç§°ï¼š")
            user_input.append(mapping[val])
        else:
            val = float(input(f"{feature}ï¼ˆæ•°å€¼å‹ï¼‰ï¼š"))
            user_input.append(val)

    # è½¬ numpy
    user_input = np.array(user_input).reshape(1, -1).astype(np.float32)

    # X æ ‡å‡†åŒ–
    user_input = scaler_x.transform(user_input)

    with torch.no_grad():
        pred_std = model(torch.tensor(user_input))

    # â˜…â˜…â˜… åæ ‡å‡†åŒ– â˜…â˜…â˜…
    pred_price = scaler_y.inverse_transform(pred_std.numpy())

    print("\n==============================")
    print(f"ğŸ  é¢„æµ‹æˆ¿ä»·ä¸ºï¼š{pred_price[0][0]:,.0f}")
    print("==============================")





if __name__ == '__main__':
    train_dataset, test_dataset, category_maps, input_dim, feature_names, scaler_x, scaler_y = creat_data()
    # print(category_maps)
    # print(input_dim)
    # print(feature_names)
    # model = ANN_house_price(input_dim)
    # print(model)

    #æ¨¡å‹è®­ç»ƒ
    # train(train_dataset, input_dim, 50)

    #æ¨¡å‹è¯„ä¼°
    # evaluate(test_dataset, input_dim)

    #æ¨¡å‹é¢„æµ‹
    # ç”¨æˆ·äº¤äº’é¢„æµ‹
    predict_house_price(input_dim, feature_names, scaler_x, scaler_y, category_maps)




